{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('tf_mac': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "5c622353f32ef24c8d83e5c3e334107c074e82d7c3e8ca52c56b9fc900ce33e6"
   }
  },
  "interpreter": {
   "hash": "5c622353f32ef24c8d83e5c3e334107c074e82d7c3e8ca52c56b9fc900ce33e6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Controller import TrainingController\n",
    "from Utils.SaveUtils import load_parameters\n",
    "from Parameters import TrainingParameters\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Show tensorboard\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs/gradient_tape\n",
    "# %tensorboard --logdir logs/gradient_tape --host localhost --port 8088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=================================================\n",
      "| Running on /job:localhost/replica:0/task:0/device:CPU:0  \n",
      "=================================================\n",
      "\n",
      "=================================================\n",
      "| Preprocessed data loaded successfully: ./datasets/preprocessed/BPI_Challenge_2012_with_resource/AOW \n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "parameters = TrainingParameters()\n",
    "tf.random.set_seed(parameters.dataset_split_seed)\n",
    "np.random.seed(parameters.dataset_split_seed)\n",
    "trainer = TrainingController(parameters = parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"baseline_lstm_with_resource\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  832       \n_________________________________________________________________\nembedding_1 (Embedding)      multiple                  2304      \n_________________________________________________________________\nlstm (LSTM)                  multiple                  24832     \n_________________________________________________________________\nlstm_1 (LSTM)                multiple                  33024     \n_________________________________________________________________\nlstm_2 (LSTM)                multiple                  24832     \n_________________________________________________________________\nlstm_3 (LSTM)                multiple                  33024     \n_________________________________________________________________\nsequential (Sequential)      (1, 1, 26)                10782     \n=================================================================\nTotal params: 129,630\nTrainable params: 129,244\nNon-trainable params: 386\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trainer.show_model_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['<PAD>',\n",
       " '<EOS>',\n",
       " '<SOS>',\n",
       " 'A_ACCEPTED_COMPLETE',\n",
       " 'A_ACTIVATED_COMPLETE',\n",
       " 'A_APPROVED_COMPLETE',\n",
       " 'A_CANCELLED_COMPLETE',\n",
       " 'A_DECLINED_COMPLETE',\n",
       " 'A_FINALIZED_COMPLETE',\n",
       " 'A_PARTLYSUBMITTED_COMPLETE',\n",
       " 'A_PREACCEPTED_COMPLETE',\n",
       " 'A_REGISTERED_COMPLETE',\n",
       " 'A_SUBMITTED_COMPLETE',\n",
       " 'O_ACCEPTED_COMPLETE',\n",
       " 'O_CANCELLED_COMPLETE',\n",
       " 'O_CREATED_COMPLETE',\n",
       " 'O_DECLINED_COMPLETE',\n",
       " 'O_SELECTED_COMPLETE',\n",
       " 'O_SENT_BACK_COMPLETE',\n",
       " 'O_SENT_COMPLETE',\n",
       " 'W_Afhandelen leads_COMPLETE',\n",
       " 'W_Beoordelen fraude_COMPLETE',\n",
       " 'W_Completeren aanvraag_COMPLETE',\n",
       " 'W_Nabellen incomplete dossiers_COMPLETE',\n",
       " 'W_Nabellen offertes_COMPLETE',\n",
       " 'W_Valideren aanvraag_COMPLETE']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "trainer.model.vocab.vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=================================================\n",
      "| Training records in logs/gradient_tape/20210618-215804 \n",
      "=================================================\n",
      "\n",
      "=================================================\n",
      "| Total epochs: 50 \n",
      "=================================================\n",
      "\n",
      "=================================================\n",
      "| Total steps: 4100 \n",
      "=================================================\n",
      "\n",
      "=================================================\n",
      "| Start epoch 0 \n",
      "=================================================\n",
      "\n",
      "=================================================\n",
      "| Start epoch 1 \n",
      "=================================================\n",
      "\n",
      "=================================================\n",
      "| Start epoch 2 \n",
      "=================================================\n",
      "\n",
      "=================================================\n",
      "| Start epoch 3 \n",
      "=================================================\n",
      "\n",
      "=================================================\n",
      "| Evaluation result | Loss [0.7043] | Accuracy [0.0730]  \n",
      "=================================================\n",
      "\n",
      "=================================================\n",
      "| Start epoch 4 \n",
      "=================================================\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/LINDA-BN-Eventlog-TF/Controller/TrainingController.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# caseids, padded_data_traces, padded_target_traces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 _, train_loss, train_accuracy = self.train_step(\n\u001b[0m\u001b[1;32m    227\u001b[0m                     \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 )\n",
      "\u001b[0;32m~/LINDA-BN-Eventlog-TF/Controller/TrainingController.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         self.optim.apply_gradients(grads_and_vars=zip(\n\u001b[1;32m    264\u001b[0m             grads, self.model.trainable_variables))\n",
      "\u001b[0;32m~/miniforge3/envs/tf_mac/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1078\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1081\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_mac/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_mac/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_aggregate_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m   \"\"\"Aggregate gradients from multiple sources.\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n=================================================\n| Model saved successfully to: ./SavedModels/0.8264_BPI2012WithResource_BaselineLSTMWithResource_2021-06-18 06:11:10.009443  \n=================================================\n"
     ]
    }
   ],
   "source": [
    "###### Save modelz\n",
    "trainer.save_training_result(\"train.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.load_trained_model(\"./SavedModels/0.7700_Diabetes_BaseNNModel_2021-05-30 04:41:24.179089\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}